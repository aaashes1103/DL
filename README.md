# CS231n: Deep Learning for Computer Vision

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-ee4c2c)
![Status](https://img.shields.io/badge/Status-In%20Progress-yellow)

My solutions and implementations for the **Stanford CS231n** course assignments. This repository contains implementations of various deep learning models, ranging from basic classifiers to state-of-the-art architectures like **Transformers**, **Diffusion Models**, and **CLIP/DINO**.

ðŸ”— **Course Website:** [https://cs231n.stanford.edu/](https://cs231n.stanford.edu/)  
ðŸ”— **Assignments:** [https://cs231n.stanford.edu/assignments.html](https://cs231n.stanford.edu/assignments.html)

## ðŸ“‚ Content

The assignments are organized as follows, covering the fundamentals of neural networks to advanced generative and self-supervised models.

### Assignment 1: Neural Network Fundamentals
- [x] **k-Nearest Neighbor (kNN)**: Implemented kNN classifier.
- [x] **Softmax Classifier**: Linear classification with Softmax loss.
- [x] **Two-Layer Neural Network**: Backpropagation implementation from scratch.
- [x] **Image Features**: Histogram of Oriented Gradients (HOG) and color histograms.
- [x] **Fully-Connected Neural Network**: Modular design for arbitrary depth networks.

### Assignment 2: CNNs & RNNs
- [x] **Batch Normalization**: Forward and backward passes for BN layers.
- [x] **Dropout**: Regularization implementation.
- [x] **Convolutional Neural Networks (CNN)**: Implemented Conv, MaxPool layers from scratch.
- [x] **PyTorch on CIFAR-10**: Training ResNet/VGG style networks using PyTorch.
- [x] **Image Captioning with Vanilla RNNs**: LSTM/RNN implementation for caption generation.

### Assignment 3: Transformers & Generative Models
- [x] **Image Captioning with Transformers**: Multi-Head Attention and Positional Encoding.
- [x] **Self-Supervised Learning**: Contrastive learning concepts.
- [x] **DDPM**: Denoising Diffusion Probabilistic Models for image generation.
- [x] **CLIP and DINO**:
    - **CLIP**: Zero-shot classification and text-image alignment.
    - **DINO**: Self-distillation with Vision Transformers and attention map visualization.